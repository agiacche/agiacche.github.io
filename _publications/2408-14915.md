---
title: "Can transformers do enumerative geometry?"
coauthors: "B. Hashemi, R. G. Corominas"
journal: "13th Int. Conf. Learn. Represent."
year: "2025"
arxiv: "2408.14915"
open: "https://openreview.net/forum?id=4X9RpKH4Ls"
git: "Baran-phys/DynamicFormer"
category: published
collection: publications
permalink: /publications/2408-14915
excerpt: 'We use transformer to compute and understand recursive patterns in $$ \psi $$-class intersection numbers, showing that the model learns key mathematical features from the data.'
date: 2024-08-27
---

How can transformers model and learn enumerative geometry? What is a robust procedure for using transformers in abductive knowledge discovery within a mathematician-machine collaboration? In this work, we introduce a transformer-based approach to computational enumerative geometry, specifically targeting the computation of $$\psi$$-class intersection numbers on the moduli space of curves. By reformulating the problem as a continuous optimization task, we compute intersection numbers across a wide value range from $$10^{-45}$$ to $$10^{-45}$$.

To capture the recursive nature inherent in these intersection numbers, we propose the Dynamic Range Activator (DRA), a new activation function that enhances the transformer's ability to model recursive patterns and handle severe heteroscedasticity. Given precision requirements for computing the numbers, we quantify the uncertainty of the predictions using conformal prediction with a dynamic sliding window adaptive to the partitions of equivalent number of marked points. To the best of our knowledge, there has been no prior work on modeling recursive functions with such a high-variance and factorial growth. Beyond simply computing intersection numbers, we explore the enumerative "world-model" of transformers. Our interpretability analysis reveals that the network is implicitly modeling the Virasoro constraints in a purely data-driven manner. Moreover, through abductive hypothesis testing, probing, and causal inference, we uncover evidence of an emergent internal representation of the the large-genus asymptotic of $$\psi$$-class intersection numbers. These findings suggest that the network internalizes the parameters of the asymptotic closed-form and the polynomiality phenomenon of intersection numbers in a non-linear manner. This opens up new possibilities in inferring asymptotic closed-form expressions directly from limited amount of data. 